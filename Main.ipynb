{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science is the interdisciplinary field that uses scientific methods, algorithms, processes, and systems to extract knowledge and insights from structured and unstructured data.\n",
      "clean and tokenized: data science interdisciplinary field us scientific method algorithm process system extract knowledge insight structured unstructured data\n",
      "\n",
      "Knowledge Engineering is a subfield of artificial intelligence (AI) that focuses on developing and maintaining knowledge-based systems, which use domain-specific knowledge to solve complex problems.\n",
      "clean and tokenized: knowledge engineering subfield artificial intelligence ai focus developing maintaining knowledgebased system use domainspecific knowledge solve complex problem\n",
      "\n",
      "In Data Science, machine learning algorithms are often used to build predictive models and make data-driven decisions.\n",
      "clean and tokenized: data science machine learning algorithm often used build predictive model make datadriven decision\n",
      "\n",
      "Knowledge Engineering involves the creation and management of knowledge bases, ontologies, and expert systems to facilitate knowledge representation and reasoning.\n",
      "clean and tokenized: knowledge engineering involves creation management knowledge base ontology expert system facilitate knowledge representation reasoning\n",
      "\n",
      "Data Scientists use programming languages like Python, R, and Julia to analyze data, create visualizations, and build machine learning models.\n",
      "clean and tokenized: data scientist use programming language like python r julia analyze data create visualization build machine learning model\n",
      "\n",
      "Knowledge Engineers work on designing knowledge acquisition systems, defining ontologies, and developing inference engines to enable automated reasoning.\n",
      "clean and tokenized: knowledge engineer work designing knowledge acquisition system defining ontology developing inference engine enable automated reasoning\n",
      "\n",
      "Data Science plays a crucial role in various industries, including healthcare, finance, marketing, and technology, by leveraging data to improve decision-making processes.\n",
      "clean and tokenized: data science play crucial role various industry including healthcare finance marketing technology leveraging data improve decisionmaking process\n",
      "\n",
      "Knowledge Engineering is fundamental in developing expert systems that can provide expert-level advice and decision support in specialized domains.\n",
      "clean and tokenized: knowledge engineering fundamental developing expert system provide expertlevel advice decision support specialized domain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# substitute this later by data from Ans\n",
    "texts = [\n",
    "    \"Data Science is the interdisciplinary field that uses scientific methods, algorithms, processes, and systems to extract knowledge and insights from structured and unstructured data.\",\n",
    "    \"Knowledge Engineering is a subfield of artificial intelligence (AI) that focuses on developing and maintaining knowledge-based systems, which use domain-specific knowledge to solve complex problems.\",\n",
    "    \"In Data Science, machine learning algorithms are often used to build predictive models and make data-driven decisions.\",\n",
    "    \"Knowledge Engineering involves the creation and management of knowledge bases, ontologies, and expert systems to facilitate knowledge representation and reasoning.\",\n",
    "    \"Data Scientists use programming languages like Python, R, and Julia to analyze data, create visualizations, and build machine learning models.\",\n",
    "    \"Knowledge Engineers work on designing knowledge acquisition systems, defining ontologies, and developing inference engines to enable automated reasoning.\",\n",
    "    \"Data Science plays a crucial role in various industries, including healthcare, finance, marketing, and technology, by leveraging data to improve decision-making processes.\",\n",
    "    \"Knowledge Engineering is fundamental in developing expert systems that can provide expert-level advice and decision support in specialized domains.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Stopwords list, yknow common words like uhh.. in the and, you get the point\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# stemmer and lemmatizer, this reduces everything to their stem by edit/removing parts of the word. choose either stemmer or lemmatizer.. \n",
    "# look up wat the difference is if you dunno but they do the same thing, in a different way. Lemmatizer better tho\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # tokenize with NLTK\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # get rid of stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # option 1: stemmer\n",
    "    # tokens = [stemmer.stem(word) for word in tokens]\n",
    "    # option 2: lemmatizer\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # there's more that we can do to make it fit our data, which we still need\n",
    "    return ' '.join(tokens)  # Return as a string for the vectorizer\n",
    "\n",
    "# preproces line by line\n",
    "preprocessed_texts = [preprocess_text(sentence) for sentence in texts]\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)  # binary=True will ensure the result is one-hot encoded\n",
    "sparse_matrix = vectorizer.fit_transform(preprocessed_texts)\n",
    "\n",
    "for textin, textclean in zip(texts, preprocessed_texts):\n",
    "    print(textin)\n",
    "    print(\"clean and tokenized:\", textclean)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data',\n",
       "  'science',\n",
       "  'interdisciplinary',\n",
       "  'field',\n",
       "  'us',\n",
       "  'scientific',\n",
       "  'method',\n",
       "  'algorithm',\n",
       "  'process',\n",
       "  'system',\n",
       "  'extract',\n",
       "  'knowledge',\n",
       "  'insight',\n",
       "  'structured',\n",
       "  'unstructured',\n",
       "  'data'],\n",
       " ['knowledge',\n",
       "  'engineering',\n",
       "  'subfield',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'ai',\n",
       "  'focus',\n",
       "  'developing',\n",
       "  'maintaining',\n",
       "  'knowledgebased',\n",
       "  'system',\n",
       "  'use',\n",
       "  'domainspecific',\n",
       "  'knowledge',\n",
       "  'solve',\n",
       "  'complex',\n",
       "  'problem'],\n",
       " ['data',\n",
       "  'science',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithm',\n",
       "  'often',\n",
       "  'used',\n",
       "  'build',\n",
       "  'predictive',\n",
       "  'model',\n",
       "  'make',\n",
       "  'datadriven',\n",
       "  'decision'],\n",
       " ['knowledge',\n",
       "  'engineering',\n",
       "  'involves',\n",
       "  'creation',\n",
       "  'management',\n",
       "  'knowledge',\n",
       "  'base',\n",
       "  'ontology',\n",
       "  'expert',\n",
       "  'system',\n",
       "  'facilitate',\n",
       "  'knowledge',\n",
       "  'representation',\n",
       "  'reasoning'],\n",
       " ['data',\n",
       "  'scientist',\n",
       "  'use',\n",
       "  'programming',\n",
       "  'language',\n",
       "  'like',\n",
       "  'python',\n",
       "  'r',\n",
       "  'julia',\n",
       "  'analyze',\n",
       "  'data',\n",
       "  'create',\n",
       "  'visualization',\n",
       "  'build',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'model'],\n",
       " ['knowledge',\n",
       "  'engineer',\n",
       "  'work',\n",
       "  'designing',\n",
       "  'knowledge',\n",
       "  'acquisition',\n",
       "  'system',\n",
       "  'defining',\n",
       "  'ontology',\n",
       "  'developing',\n",
       "  'inference',\n",
       "  'engine',\n",
       "  'enable',\n",
       "  'automated',\n",
       "  'reasoning'],\n",
       " ['data',\n",
       "  'science',\n",
       "  'play',\n",
       "  'crucial',\n",
       "  'role',\n",
       "  'various',\n",
       "  'industry',\n",
       "  'including',\n",
       "  'healthcare',\n",
       "  'finance',\n",
       "  'marketing',\n",
       "  'technology',\n",
       "  'leveraging',\n",
       "  'data',\n",
       "  'improve',\n",
       "  'decisionmaking',\n",
       "  'process'],\n",
       " ['knowledge',\n",
       "  'engineering',\n",
       "  'fundamental',\n",
       "  'developing',\n",
       "  'expert',\n",
       "  'system',\n",
       "  'provide',\n",
       "  'expertlevel',\n",
       "  'advice',\n",
       "  'decision',\n",
       "  'support',\n",
       "  'specialized',\n",
       "  'domain']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Frequencies:\n",
      "d: 49\n",
      "a: 68\n",
      "t: 55\n",
      " : 114\n",
      "s: 48\n",
      "c: 40\n",
      "i: 92\n",
      "e: 133\n",
      "n: 89\n",
      "r: 45\n",
      "p: 22\n",
      "l: 51\n",
      "y: 13\n",
      "f: 12\n",
      "u: 24\n",
      "m: 27\n",
      "h: 10\n",
      "o: 54\n",
      "g: 46\n",
      "x: 5\n",
      "k: 15\n",
      "w: 11\n",
      "b: 7\n",
      "v: 15\n",
      "j: 1\n",
      "z: 3\n",
      "q: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(word for tokens in preprocessed_texts for word in tokens)\n",
    "\n",
    "\n",
    "print(\"\\nWord Frequencies:\")\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
